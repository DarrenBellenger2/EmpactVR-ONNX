# EmpactVR-ONNX

EMPACTVR is a research project to integrate bi-modal (facial and audio) emotion recognition, into a metaverse or game platform. This is the second (production) version of EMPACTVR.

This project contains 2 ONNX ML models (for face and audio emotion recognition), along with samples of how they may be used within a Unity-based VR/metaverse or game environment.

# Pre-requisites

Please follow the pre-requisites outlined in the earlier MLP version. In addition the python development of the ONNX models will require the Pytorch environment.

All Unity examples require Unity version 2022.3.16f1 and utlise the Homuler (open source Github package) for integration with Google FaceMesh Version 2.
